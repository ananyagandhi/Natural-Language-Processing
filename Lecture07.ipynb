{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48fe930c",
   "metadata": {},
   "source": [
    "# Lecture 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdec3c5c",
   "metadata": {},
   "source": [
    "## Parsing with CFGs and PCFGs: the CKY Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4eae92",
   "metadata": {},
   "source": [
    "### Two Approaches to CFG Parsing\n",
    "1. Bottom-up: start with the words (terminal symbols) and see which subtrees you can build, then combine subtrees into larger trees (process is driven by the input sentence)\n",
    "    * CKY Algorithm - requires grammars to be in Chomsky Normal Form\n",
    "2. Top-down: start at the start symbol (S), try to apply prouction rules that are compatible with the input (process is driven by the grammar). \n",
    "    * Earley Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebcaeea",
   "metadata": {},
   "source": [
    "### Chomsky Normal Form\n",
    "* A CFG $G = (N, \\Sigma, R, S)$ is in Chomsky Normal Form (CNF) if the rules take one of the following forms:\n",
    "    * $A \\rightarrow B C$ where $A, B, C \\in N$\n",
    "    * $A \\rightarrow a$ where $A \\in N, b \\in \\Sigma$\n",
    "\n",
    "* If a rule derives two variables, they must both be nonterminals\n",
    "* If a rule derives a single variable, it must be terminal\n",
    "* Any CFG can be converted to a grammar in CNF that represents the same language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136208c",
   "metadata": {},
   "source": [
    "### Cocke-Kasami-Younger (CKY) Algorithm - Motivation\n",
    "* A nonterminal A covers a sub-span $s[i, j]$ of the input string $s$ if the rules in the grammar can derive $s[i, j]$ from A\n",
    "* Let $\\pi[i, j]$ be the set of nonterminals that cover $[i, j]$\n",
    "\n",
    "* The string is recognized by the grammar if $S \\in \\pi[i, j]$\n",
    "\n",
    "* Approach: compute $\\pi[i, j]$ from the bottom-up, using dynamic programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c3daf",
   "metadata": {},
   "source": [
    "### CKY - Recursive Definition\n",
    "* To compute $\\pi[i, j]$, try all possible split points $k$ such that $i < k < j$\n",
    "    * For each $k$, check if the nonterminals in $\\pi[i, k]$ and $\\pi[k, j]$ match any of the rules in the grammar\n",
    "    * Update $\\pi[i, j]$ to include any new rules found "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b76f6db",
   "metadata": {},
   "source": [
    "### Syntactic Ambiguity\n",
    "* Multiple parse trees for the same sentence/phrase indicates that the phrase can be interpreted in multiple ways (depending on emphasis)\n",
    "* Construct parse trees from the CKY Algorithm by storing backpointers, in addition to the nonterminals that derive the variables at every step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8cf751",
   "metadata": {},
   "source": [
    "### Probabilities for Parse Trees\n",
    "* In order to select a parse tree (there may be infinitely many generated by a grammar G), we must assign a probability to each parse tree\n",
    "* Sum of probabilities of all parse trees should be 1\n",
    "\n",
    "\n",
    "* The most likely parse tree produced by $G$ for string $s$ is:\n",
    "\n",
    "$$\n",
    "\\arg \\max_{t \\in T_G(s)} P(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb299d",
   "metadata": {},
   "source": [
    "### Probabilistic Context Free Grammars (PCFG)\n",
    "* A PCFG consists of a Context Free Grammar where there is a probability $P(A \\rightarrow \\beta)$ for each rule\n",
    "* The probabilities for all rules with the same left-hand-side sum up to 1:\n",
    "\n",
    "$$\n",
    "\\sum_{\\beta} P(A \\rightarrow \\beta) = 1\n",
    "$$\n",
    "\n",
    "sum over all $\\beta$ generated by $A$ and the sum should equal 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1296f3f",
   "metadata": {},
   "source": [
    "### Estimating PCFG Probabilities\n",
    "* Supervised training: we can estimate PCFG probabilities from a *treebank*, a corpus manually annotated with constituency structure using maximum likelihood estimates:\n",
    "\n",
    "$$ P(A \\rightarrow \\beta) = \\frac{count(A \\rightarrow \\beta)}{count(A)}\n",
    "$$\n",
    "\n",
    "* Can also apply smoothing and other techniques in case any tokens are unseen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1c1fd9",
   "metadata": {},
   "source": [
    "### CKY for PCFG Parsing\n",
    "* Adapt the CKY algorithm to construct the most likely parse tree -- at each step, store the rule that has the highest probability at location i, j\n",
    "\n",
    "$$\n",
    "\\pi[i, j, X] = \\max_{t \\in T_G(s[i,j]) : root(t) = X} P(t)\n",
    "$$\n",
    "\n",
    "At each location [i,j] and for each rule X, store the rule $X \\rightarrow \\beta$ if this rule has the greatest probability out of all rules with X on the LHS\n",
    "\n",
    "* Recursive definition:\n",
    "\n",
    "Base case: $\\pi[i, i + 1, A] = \\begin{cases} P(A \\rightarrow s_i) & \\text{if } A \\rightarrow s_i \\in R \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}$\n",
    "\n",
    "$$\n",
    "\\pi[i, j, A] = \\max_{k=i + 1, ..., j-1} P(A \\rightarrow BC) \\cdot \\pi[i, k, B] \\cdot \\pi[k, j, C]\n",
    "$$\n",
    "\n",
    "for all $ A \\rightarrow BC  \\in R$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
